# 第七章 缺失数据

## 一、缺失值的统计和删除

### 1、缺失信息的统计

缺失数据可以用`isna`或`isnull`（两个函数没有区别）来查看每个单元格是否缺失，通过和`sum`的组合可以计算出每列缺失值的比例：

``` python
df = pd.read_csv('joyful-pandas/data/learn_pandas.csv', usecols = ['Grade', 'Name', 'Gender', 'Height', 'Weight', 'Transfer'])
df.isna().head()
```

|      | Grade |  Name | Gender | Height | Weight | Transfer |
| ---: | ----: | ----: | -----: | -----: | -----: | -------: |
|    0 | False | False |  False |  False |  False |    False |
|    1 | False | False |  False |  False |  False |    False |
|    2 | False | False |  False |  False |  False |    False |
|    3 | False | False |  False |   True |  False |    False |
|    4 | False | False |  False |  False |  False |    False |

``` python
df.isna().sum()/df.shape[0] # 查看缺失的比例
```

```
Grade       0.000
Name        0.000
Gender      0.000
Height      0.085
Weight      0.055
Transfer    0.060
dtype: float64
```

如果想要查看某一列缺失或者非缺失的行，可以利用`Series`上的`isna`或者`notna`进行布尔索引。例如，查看身高缺失的行：

``` python
df[df.Height.isna()].head()
```

|      |     Grade |         Name | Gender | Height | Weight | Transfer |
| ---: | --------: | -----------: | -----: | -----: | -----: | -------: |
|    3 | Sophomore | Xiaojuan Sun | Female |    NaN |   41.0 |        N |
|   12 |    Senior |     Peng You | Female |    NaN |   48.0 |      NaN |
|   26 |    Junior |    Yanli You | Female |    NaN |   48.0 |        N |
|   36 |  Freshman | Xiaojuan Qin |   Male |    NaN |   79.0 |        Y |
|   60 |  Freshman |   Yanpeng Lv |   Male |    NaN |   65.0 |        N |

如果想要同时对几个列，检索出全部为缺失或者至少有一个缺失或者没有缺失的行，可以使用`isna, notna`和`any, all`的组合。例如，对身高、体重和转系情况这3列分别进行这三种情况的检索：

``` python
sub_set = df[['Height', 'Weight', 'Transfer']]
df[sub_set.isna().all(1)] # 全部缺失
```

|      |  Grade |         Name | Gender | Height | Weight | Transfer |
| ---: | -----: | -----------: | -----: | -----: | -----: | -------: |
|  102 | Junior | Chengli Zhao |   Male |    NaN |    NaN |      NaN |

``` python
df[sub_set.isna().any(1)].head() # 至少有一个缺失
```

|      |     Grade |          Name | Gender | Height | Weight | Transfer |
| ---: | --------: | ------------: | -----: | -----: | -----: | -------: |
|    3 | Sophomore |  Xiaojuan Sun | Female |    NaN |   41.0 |        N |
|    9 |    Junior |       Juan Xu | Female |  164.8 |    NaN |        N |
|   12 |    Senior |      Peng You | Female |    NaN |   48.0 |      NaN |
|   21 |    Senior | Xiaopeng Shen |   Male |  166.0 |   62.0 |      NaN |
|   26 |    Junior |     Yanli You | Female |    NaN |   48.0 |        N |

``` python
df[sub_set.notna().all(1)].head() # 没有缺失
```

|      |     Grade |           Name | Gender | Height | Weight | Transfer |
| ---: | --------: | -------------: | -----: | -----: | -----: | -------: |
|    0 |  Freshman |   Gaopeng Yang | Female |  158.9 |   46.0 |        N |
|    1 |  Freshman | Changqiang You |   Male |  166.5 |   70.0 |        N |
|    2 |    Senior |        Mei Sun |   Male |  188.9 |   89.0 |        N |
|    4 | Sophomore |    Gaojuan You |   Male |  174.0 |   74.0 |        N |
|    5 |  Freshman |    Xiaoli Qian | Female |  158.0 |   51.0 |        N |

### 2、缺失信息的删除

数据处理中经常需要根据缺失值的大小、比例或其他特征来进行样本或列特征的删除，`pandas`中提供了`dropna`函数来进行操作。

`dropna`的主要参数为轴方向`axis`（默认为0，即删除行）、删除方式`how`、删除的非缺失个数阈值`thresh`（非缺失值没有达到这个数量的相应维度会被删除）、备选的删除子集`subset`，其中`how`主要有`any`和`all`两种参数可以选择。

例如，删除身高体重至少有一个缺失的行：

``` python
res = df.dropna(how = 'any', subset = ['Height', 'Weight'])
res.shape
```

```
(174, 6)
```

删除超过15个缺失值的列：

``` python
res = df.dropna(1, thresh=df.shape[0]-15) # 身高被删除
res.head()
```

|      |     Grade |           Name | Gender | Weight | Transfer |
| ---: | --------: | -------------: | -----: | -----: | -------: |
|    0 |  Freshman |   Gaopeng Yang | Female |   46.0 |        N |
|    1 |  Freshman | Changqiang You |   Male |   70.0 |        N |
|    2 |    Senior |        Mei Sun |   Male |   89.0 |        N |
|    3 | Sophomore |   Xiaojuan Sun | Female |   41.0 |        N |
|    4 | Sophomore |    Gaojuan You |   Male |   74.0 |        N |

当然，不用`dropna`同样是可行的，例如上述的两个操作，也可以使用布尔索引来完成：

``` python
res = df.loc[df[['Height', 'Weight']].notna().all(1)]
res.shape
```

```
(174, 6)
```

``` python
res = df.loc[:, ~(df.isna().sum()>15)]
res.head()
```

|      |     Grade |           Name | Gender | Weight | Transfer |
| ---: | --------: | -------------: | -----: | -----: | -------: |
|    0 |  Freshman |   Gaopeng Yang | Female |   46.0 |        N |
|    1 |  Freshman | Changqiang You |   Male |   70.0 |        N |
|    2 |    Senior |        Mei Sun |   Male |   89.0 |        N |
|    3 | Sophomore |   Xiaojuan Sun | Female |   41.0 |        N |
|    4 | Sophomore |    Gaojuan You |   Male |   74.0 |        N |

## 二、缺失值的填充和插值

### 1、利用fillna进行填充

在`fillna`中有三个参数是常用的：`value, method, limit`。其中，`value`为填充值，可以是标量，也可以是索引到元素的字典映射；`method`为填充方法，有用前面的元素填充`ffill`和用后面的元素填充`bfill`两种类型，`limit`参数表示连续缺失值的最大填充次数。

下面构造一个简单的`Series`来说明用法：

``` python
s = pd.Series([np.nan, 1, np.nan, np.nan, 2, np.nan], list('aaabcd'))
s
```

```python
a    NaN
a    1.0
a    NaN
b    NaN
c    2.0
d    NaN
dtype: float64
```

``` python
s.fillna(method='ffill') # 用前面的值向后填充
```

```
a    NaN
a    1.0
a    1.0
b    1.0
c    2.0
d    2.0
dtype: float64
```

``` python
s.fillna(method='ffill', limit=1) # 连续出现的缺失，最多填充一次
```

```
a    NaN
a    1.0
a    1.0
b    NaN
c    2.0
d    2.0
dtype: float64
```

``` python
s.fillna(s.mean()) # value为标量
```

```
a    1.5
a    1.0
a    1.5
b    1.5
c    2.0
d    1.5
dtype: float64
```

``` python
s.fillna({'a': 100, 'd': 200}) # 通过索引映射填充的值
```

```
a    100.0
a      1.0
a    100.0
b      NaN
c      2.0
d    200.0
dtype: float64
```

有时为了更加合理地填充，需要先进行分组后再操作。例如，根据年级进行身高的均值填充：

``` python
df.groupby('Grade')['Height'].transform(lambda x: x.fillna(x.mean())).head()
```

```
0    158.900000
1    166.500000
2    188.900000
3    163.075862
4    174.000000
Name: Height, dtype: float64
```

#### 【练一练】

对一个序列以如下规则填充缺失值：如果单独出现的缺失值，就用前后均值填充，如果连续出现的缺失值就不填充，即序列`[1, NaN, 3, NaN, NaN]`填充后为`[1, 2, 3, NaN, NaN]`，请利用`fillna`函数实现。（提示：利用`limit``参数）

``` python
s = pd.Series([ 1, np.nan, 3, np.nan, np.nan])
s
```

```
0    1.0
1    NaN
2    3.0
3    NaN
4    NaN
dtype: float64
```

``` python
(s.fillna(method='ffill',limit=1)+s.fillna(method='bfill',limit=1))/2
```

```
0    1.0
1    2.0
2    3.0
3    NaN
4    NaN
dtype: float64
```

### 2. 插值函数

在关于`interpolate`函数的 `文档 <https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate>`__ 描述中，列举了许多插值法，包括了大量`Scipy`中的方法。由于很多插值方法涉及到比较复杂的数学知识，因此这里只讨论比较常用且简单的三类情况，即线性插值、最近邻插值和索引插值。

对于`interpolate`而言，除了插值方法（默认为`linear`线性插值）之外，有与`fillna`类似的两个常用参数，一个是控制方向的`limit_direction`，另一个是控制最大连续缺失值插值个数的`limit`。其中，限制插值的方向默认为`forward`，这与`fillna`的`method`中的`ffill`是类似的，若想要后向限制插值或者双向限制插值可以指定为`backward`或`both`。

``` python
s = pd.Series([np.nan, np.nan, 1, np.nan, np.nan, np.nan, 2, np.nan, np.nan])
s.values
# array([nan, nan,  1., nan, nan, nan,  2., nan, nan])
```

例如，在默认线性插值法下分别进行`backward`和双向限制插值，同时限制最大连续条数为1：

``` python
res = s.interpolate(limit_direction='backward', limit=1)
res.values
# array([ nan, 1.  , 1.  ,  nan,  nan, 1.75, 2.  ,  nan,  nan])
```

``` python
res = s.interpolate(limit_direction='both', limit=1)
res.values
# array([ nan, 1.  , 1.  , 1.25,  nan, 1.75, 2.  , 2.  ,  nan])
```

第二种常见的插值是最近邻插补，即缺失值的元素和离它最近的非缺失值元素一样：

``` python
s.interpolate('nearest').values
# array([nan, nan,  1.,  1.,  1.,  2.,  2., nan, nan])
```

最后来介绍索引插值，即根据索引大小进行线性插值。例如，构造不等间距的索引进行演示：

``` python
s = pd.Series([0,np.nan,10],index=[0,1,10])
s
```

``` python
s.interpolate() # 默认的线性插值，等价于计算中点的值
```

```
0     NaN
1     NaN
2    1.00
3    1.25
4    1.50
5    1.75
6    2.00
7    2.00
8    2.00
dtype: float64
```

``` python
s.interpolate(method='index') # 和索引有关的线性插值，计算相应索引大小对应的值
```

```
0      0.0
1      1.0
10    10.0
dtype: float64
```

同时，这种方法对于时间戳索引也是可以使用的，有关时间序列的其他话题会在第十章进行讨论，这里举一个简单的例子：

``` python
s = pd.Series([0,np.nan,10], index=pd.to_datetime(['20200101', '20200102', '20200111']))
s
```

```
2020-01-01     0.0
2020-01-02     NaN
2020-01-11    10.0
dtype: float64
```

#### 【NOTE】关于polynomial和spline插值的注意事项

在`interpolate`中如果选用`polynomial`的插值方法，它内部调用的是`scipy.interpolate.interp1d(*,*,kind=order)`，这个函数内部调用的是`make_interp_spline`方法，因此其实是样条插值而不是类似于`numpy`中的`polyfit`多项式拟合插值；而当选用`spline`方法时，`pandas`调用的是`scipy.interpolate.UnivariateSpline`而不是普通的样条插值。这一部分的文档描述比较混乱，而且这种参数的设计也是不合理的，当使用这两类插值方法时，用户一定要小心谨慎地根据自己的实际需求选取恰当的插值方法。

## 三、Nullable类型

### 1. 缺失记号及其缺陷

在`python`中的缺失值用`None`表示，该元素除了等于自己本身之外，与其他任何元素不相等：

``` python
None == None
# True
None == False
# False
None == []
# False
None == ''
# False
```

在`numpy`中利用`np.nan`来表示缺失值，该元素除了不和其他任何元素相等之外，和自身的比较结果也返回`False`。

值得注意的是，虽然在对缺失序列或表格的元素进行比较操作的时候，`np.nan`的对应位置会返回`False`，但是在使用`equals`函数进行两张表或两个序列的相同性检验时，会自动跳过两侧表都是缺失值的位置，直接返回`True`：

``` python
s1 = pd.Series([1, np.nan])
s2 = pd.Series([1, 2])
s3 = pd.Series([1, np.nan])
s1 == 1
# 0     True
# 1    False
# dtype: bool
```

``` python
s1.equals(s2)
# False
s1.equals(s3)
# True
```

在时间序列的对象中，`pandas`利用`pd.NaT`来指代缺失值，它的作用和`np.nan`是一致的（时间序列的对象和构造将在第十章讨论）：

``` python
pd.to_timedelta(['30s', np.nan]) # Timedelta中的NaT
# TimedeltaIndex(['0 days 00:00:30', NaT], dtype='timedelta64[ns]', freq=None)
pd.to_datetime(['20200101', np.nan]) # Datetime中的NaT
# DatetimeIndex(['2020-01-01', 'NaT'], dtype='datetime64[ns]', freq=None)
```

那么为什么要引入`pd.NaT`来表示时间对象中的缺失呢？仍然以`np.nan`的形式存放会有什么问题？在`pandas`中可以看到`object`类型的对象，而`object`是一种混杂对象类型，如果出现了多个类型的元素同时存储在`Series`中，它的类型就会变成`object`。例如，同时存放整数和字符串的列表：

``` python
pd.Series([1, 'two'])
# 0      1
# 1    two
# dtype: object
```

